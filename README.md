# Streamwater Project â€” DISCO

**DISCO (DIstributional Subgroup Clustering for Online Imputation)** is a fast and scalable framework for **batch time-series imputation** of water consumption data.

The method leverages **frequency-distribution clustering of behavioural subgroups** across **hourly, daily, weekly and monthly patterns**.

---

# ðŸ“¦ Project Structure

```text
.
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ data_analysis.ipynb      # Clustering + statistics warm-up (run once)
â”‚   â””â”€â”€ impute_ts.py             # Batch imputation pipeline
â”‚
â”œâ”€â”€ Data
â”‚   â”œâ”€â”€ Contadores.xlsx          # Static input
â”‚   â”œâ”€â”€ TelemetriaConsumosVilaSol_v2.csv  # Static input
â”‚   â””â”€â”€ inputs_ts.csv            # âš™ï¸ Generated by notebook
â”‚
â”œâ”€â”€ variables
â”‚   â””â”€â”€ variables.pkl            # âš™ï¸ Generated by notebook
â”‚
â””â”€â”€ README.md
```

---

# 1ï¸âƒ£ Clustering & Warm-Up â€” `src/data_analysis.ipynb`

This notebook prepares the historical dataset and builds the **distributional subgroup clusters** used during imputation. Its output (`variables.pkl`) defines the group/subgroup structure that `impute_ts.py` loads at startup. It only needs to be re-run if consumption patterns change significantly.

> **Note on statistics warm-up:** `impute_ts.py` initialises all statistics from scratch and updates them as it processes each record â€” this is the warm-up phase. If you want to adapt the script for **true online (stream) imputation**, `impute_ts.py` should first be run in warm-up mode (`skip=True`) on historical data to build up the statistics before serving live imputation requests.

## Input Datasets

### `Contadores.xlsx`
Metadata for each **Point of Consumption (LC)**:
- `contact_id`
- `tipo_consumo` (Type of Consumption)

### `TelemetriaConsumosVilaSol_v2.csv`
Hourly cumulative meter readings:

| Column | Description |
|---|---|
| id | Meter ID |
| contact_id | Point of Consumption ID |
| calibre | Nominal diameter (mm) |
| data_instalacao | Installation date |
| data | Day of consumption |
| index_0 â€“ index_23 | Hourly cumulative values |

---

## ðŸ”„ Data Transformation

Daily cumulative readings are converted into an **hourly time-series dataset**:

`seq_all_df` â†’ exported as `inputs_ts.csv`

### Final Schema (1 row per hour)

**Metadata:** `id`, `contact_id`, `calibre`, `data_instalacao`, `tipo_consumo`

**Time features:** `hour`, `month`, `month_name`, `day_of_week`, `day_name`

**Consumption:** `cumulative_value`, `consumption` (hourly usage)

---

## ðŸ§  Clustering Strategy

Clustering is performed using a **two-level hierarchical grouping**.

### Group Level
`(tipo_consumo, calibre)` â€” e.g., ("DomÃ©stico", 15)

### Subgroup Level
`(month, day_of_week, hour)` â€” a specific temporal context within a group.

### Data Structure

The clustering output is a **list of lists**. Each index corresponds to one group and contains a list of dictionaries â€” one per subgroup. Each dictionary has the following keys:

```python
{
    "months":  [...],   # list of months this subgroup covers
    "days":    [...],   # list of weekdays this subgroup covers
    "hours":   [...],   # list of hours this subgroup covers
    "df":      ...      # DataFrame of all observations matching this subgroup
}
```

### Stored Artefacts

Saved to `variables/variables.pkl`. This file is loaded once by `impute_ts.py` and is not modified during imputation.

Contents:
- List of subgroup dictionaries (as described above)
- `idx2pair` â†’ index â†’ `(tipo_consumo, calibre)`
- `pair2idx` â†’ `(tipo_consumo, calibre)` â†’ index

---

# 2ï¸âƒ£ Imputation â€” `src/impute_ts.py`

This script performs **batch imputation** over the full `inputs_ts.csv` dataset, processing records sequentially. Optionally, it also applies applies range corrections upon True value and rebuilds cumulative values.

## âš™ï¸ Script Parameters

| Parameter | Description | Default |
|---|---|---|
| `data` | Path to `variables.pkl` warm-up file | required |
| `input_csv` | Path to hourly time-series file | required |
| `weight_contact` | Weight given to the LC's own history when blending with subgroup data at Level 1. `(1 - weight_contact)` is the subgroup's weight. | 0.7 |
| `ewma_alpha` | EWMA decay factor Î± | 0.1 |
| `skip` | If `True`, only updates statistics without imputing or post-processing | `False` |

**The script performs the following steps:**
1. Iterates through the dataset, imputing missing values and updating warm-up statistics.
2. Applies range corrections upon True value (optional, skipped if `skip=True`).
3. Rebuilds cumulative values (optional, skipped if `skip=True`).

---

## ðŸ”„ Belief Update Logic

Two beliefs are maintained and updated at each time step `t`:

### 1. LC (Point of Consumption) Belief

```
Î¼(t)_LC = (1 - Î±) Â· Î¼(t-1)_LC + Î± Â· x(t)_LC
```

- `x(t)_LC`: true hourly consumption of the LC at time `t`
- `Î±` (`ewma_alpha`): controls how fast the belief adapts to new observations
- Each LC maintains a **separate belief per subgroup** it appears in.

### 2. Subgroup Belief

```
Î¼(t)_subgroup = (1 - Î±) Â· Î¼(t-1)_subgroup + Î± Â· xÌ„(t)_subgroup
```

- `xÌ„(t)_subgroup`: mean consumption across all LCs in that subgroup at time `t`

### Initialisation

All belief values (`pop_mean`, `ewma_mean`, `ewma_var`, `ewma_std`) are initialised to **0**. `count` is initialised to **1** to avoid division-by-zero on the first update.

---

## ðŸ” Imputation Fallback Strategy

DISCO uses a **4-level hierarchical fallback** to guarantee robustness. Each imputed value is tagged with the level used, enabling full traceability.

### Warm-Up Data Structures (updated during imputation)

| Structure | Key | Description |
|---|---|---|
| `subgroup_stats` | `(pair_idx, subgroup_idx)` | Statistics for a subgroup within a group |
| `contact_stats` | `(contact_id, pair_idx, subgroup_idx)` | Statistics for a specific LC in a specific subgroup |
| `contact_pair_stats` | `(contact_id, pair_idx)` | Statistics for a specific LC across all subgroups |
| `pair_stats` | `pair_idx` | Global statistics for a group across all subgroups |

Each structure stores: `pop_mean`, `pop_var`, `ewma_mean`, `ewma_var`, `ewma_std`, `count`.

### Imputation Levels

| Level | Name | Description |
|---|---|---|
| **1 (Default)** | `contact_subgroup` | Blends the LC's own subgroup history with the subgroup's general distribution, weighted by `weight_contact` and `(1 - weight_contact)` respectively. |
| **2** | `only_subgroup` | Uses the subgroup distribution for the group `(tipo_consumo, calibre)`, ignoring LC history entirely. Used when the LC has no history for this subgroup. |
| **3** | `only_contact` | Uses the LC's historical behaviour across **all subgroups**. Used when no subgroup data is available. |
| **4** | `only_group` | Uses the global distribution for the group `(tipo_consumo, calibre)`. Most generic fallback. |

> **Note on unseen LCs:** A `contact_id` not present in the warm-up data will naturally have no `contact_stats`, so Level 1 fails and imputation falls through to Level 2 or beyond automatically.

If no level produces a value, the consumption is left **missing**.

---

# ðŸ“Š Best Hyperparameters per Group

Only groups with validated weights are shown.

| Type of Consumption | Calibre | weight_contact | ewma_alpha |
|---|---|---|---|
| Irrigation Inframoura | 40 | 0.1 | 0.1 |
| Commerce | 15 | 0.9 | 0.9 |
| Domestic | 15 | 0.9 | 0.9 |
| Services-Condominium | 15 | 0.3 | 0.3 |
| Industry | 15 | 0.7 | 0.9 |
| Services-Condominium | 20 | 0.7 | 0.5 |
| Industry | 50 | 0.5 | 0.9 |
| Industry | 40 | 0.9 | 0.9 |
| Industry | 20 | 0.7 | 0.7 |
| Commerce | 40 | 0.1 | 0.1 |
| Irrigation Inframoura | 15 | 0.1 | 0.1 |
| Services 2nd Meter â€“ Condominium Irrigation | 50 | 0.7 | 0.9 |
| Industry without MSW | 80 | 0.1 | 0.7 |
| Services-Condominium | 65 | 0.7 | 0.3 |
| Services-Condominium | 100 | 0.9 | 0.7 |
| Irrigation-Domestic | 20 | 0.9 | 0.3 |
| Domestic | 20 | 0.9 | 0.9 |
| Non-Domestic â€“ Irrigation | 20 | 0.9 | 0.7 |
| Irrigation-Domestic | 15 | 0.1 | 0.1 |
| Irrigation Inframoura | 30 | 0.1 | 0.3 |
| Industry | 30 | 0.3 | 0.9 |
| Public Utility Institutions | 15 | 0.1 | 0.1 |
| Irrigation Inframoura | 20 | 0.1 | 0.5 |
| Services 2nd Meter â€“ Condominium Irrigation | 80 | 0.1 | 0.3 |
| Services 2nd Meter â€“ Condominium Irrigation | 40 | 0.1 | 0.3 |
| Industry | 25 | 0.1 | 0.1 |
| Industry Inframoura | 15 | 0.1 | 0.5 |
| Construction Works | 15 | 0.1 | 0.1 |
| Services-Condominium | 80 | 0.1 | 0.9 |
| Construction Works | 20 | 0.1 | 0.7 |

---

# ðŸš€ Summary

DISCO enables:
- **Behaviour-aware clustering** for precise temporal profiling.
- **Batch imputation** with adaptive statistics that update as the dataset is processed.
- **Robust fallback** across 4 specificity levels to handle any LC, including unseen ones.
- **EWMA corrections** to follow consumption pattern shifts over time.
- **Full traceability** â€” every imputed value is tagged with the level used.
